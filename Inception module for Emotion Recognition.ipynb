{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import BatchNormalization, Input,Conv2D, Activation, MaxPooling2D,MaxPooling2D,AveragePooling2D, Dense, GlobalAveragePooling2D\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout, Flatten, Concatenate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import keras_resnet.models\n",
    "import keras\n",
    "from keras import callbacks\n",
    "from keras.models import model_from_json\n",
    "import h5py\n",
    "tbCallBack = callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0                                1         2\n",
      "0  user.id                            image   emotion\n",
      "1      628  facial-expressions_2868588k.jpg     anger\n",
      "2      628  facial-expressions_2868585k.jpg  surprise\n",
      "3      628  facial-expressions_2868584k.jpg   disgust\n",
      "4      628  facial-expressions_2868582k.jpg      fear\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('legend.csv',header = None)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack([cv2.imread('finalimages\\\\'+str(img)) for img in df.iloc[10:4010,1]]).astype(np.float)[:,:,:,np.newaxis]\n",
    "x_t = np.stack([cv2.imread('finalimages\\\\'+str(img1)) for img1 in df.iloc[4100:4600,1]]).astype(np.float)[:,:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.vstack(df.iloc[10:4010,-1].values)\n",
    "y_t = np.vstack(df.iloc[4100:4600,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y.reshape(4000,)\n",
    "y_test = y_t.reshape(500,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 5 5 4 0 4 5 5 5 5 5 7 4 5 5 7 5 4 4 4 4 5 5 5 5 5 5 5 5 4 4 5 5 4 5 5\n",
      " 5 5 5 5 5 7 5 5 5 5 5 7 5 7 5 5 0 5 7 5 7 7 5 5 5 5 5 5 5 5 5 5 5 5 5 4 5\n",
      " 5 5 5 5 5 5 5 5 5 5 4 5 5 4 5 5 5 5 4 5 4 5 5 5 5 5 5 5 5 5 4 7 5 5 5 5 4\n",
      " 5 5 5 5 5 4 4 5 5 5 4 4 5 4 5 5 5 5 5 5 6 5 5 5 5 4 4 5 4 5 5 5 5 5 4 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 4 5 5 5 5 5 5 7 5 5 5 5 5 5 4 5 5 5 4 5 5 4 4 5 5 7 5\n",
      " 7 5 4 5 0 4 4 4 5 5 5 5 4 5 5 0 5 5 4 7 5 4 0 7 5 5 7 5 5 5 5 5 7 5 5 5 5\n",
      " 5 4 5 4 4 5 6 4 5 5 5 5 4 4 7 4 4 4 7 5 5 5 5 4 5 5 5 5 4 4 4 4 4 6 4 4 5\n",
      " 4 6 5 4 4 5 5 4 4 4 4 5 4 5 4 5 5 5 4 4 4 5 5 4 4 5 5 5 5 5 6 4 5 5 4 4 5\n",
      " 5 5 5 5 4 4 5 4 5 5 5 4 4 4 4 5 5 4 5 5 0 5 4 4 4 4 5 5 5 4 4 4 4 4 4 4 4\n",
      " 5 5 5 5 0 4 5 0 5 5 4 5 4 5 5 5 5 4 4 5 5 7 4 4 5 4 4 4 4 5 5 5 5 5 5 5 5\n",
      " 3 5 5 5 5 4 4 4 4 5 4 4 5 5 4 5 5 5 5 4 4 4 4 4 5 5 4 4 4 4 5 4 5 4 5 4 4\n",
      " 4 5 4 0 4 5 5 4 5 5 4 5 0 5 4 4 5 5 7 5 4 4 4 4 5 5 4 7 4 4 4 4 4 5 4 4 4\n",
      " 4 4 4 4 5 5 5 5 5 4 7 4 4 5 5 4 5 4 4 4 4 4 4 5 4 5 4 5 5 4 5 5 5 5 5 5 5\n",
      " 4 4 5 4 4 5 5 4 5 5 4 4 4 5 4 4 5 4 4]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y1 = np_utils.to_categorical(encoded_Y)\n",
    "encoder.fit(y_train)\n",
    "encoded_Y1 = encoder.transform(y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y2 = np_utils.to_categorical(encoded_Y1)\n",
    "print(encoded_Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X / 255\n",
    "X_test = x_t / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(4000,128,128,3)\n",
    "X_test = X_test.reshape(500,128,128,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(128,128,3))\n",
    "num_classes = 8\n",
    "num_filter = 64\n",
    "x1 = Conv2D(8,(7,7),strides=(2,2),kernel_initializer='glorot_uniform',activation='relu')(inputs)\n",
    "x1 = MaxPooling2D(pool_size=(3,3),padding='same', strides = (2,2))(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = Conv2D(16,(1,1),strides=(1,1),kernel_initializer='glorot_uniform',activation='relu')(x1)\n",
    "x1 = Conv2D(32,(3,3),strides=(1,1),kernel_initializer='glorot_uniform',activation='relu')(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(3,3),padding='same', strides = (2,2))(x1)\n",
    "\n",
    "tower1 = Conv2D(filters = num_filter, kernel_size=(1,1),padding='same',kernel_initializer='glorot_uniform', activation='relu')(x1)\n",
    "tower1 = Conv2D(filters = num_filter, kernel_size=(3,3),padding='same',kernel_initializer='glorot_uniform', activation='relu')(tower1)\n",
    "\n",
    "tower2 = Conv2D(filters = num_filter, kernel_size=(1,1),padding='same',kernel_initializer='glorot_uniform',activation='relu')(x1)\n",
    "tower2 = Conv2D(filters = num_filter, kernel_size=(5,5),padding='same',kernel_initializer='glorot_uniform', activation='relu')(tower2)\n",
    "\n",
    "tower3 = MaxPooling2D(pool_size=(3,3),padding='same', strides = (1,1))(x1)\n",
    "tower3 = Conv2D(filters = num_filter, kernel_size=(3,3),padding='same',kernel_initializer='glorot_uniform', activation='relu')(tower3)\n",
    "tower4 = Conv2D(filters = num_filter, kernel_size=(3,3),padding='same',kernel_initializer='glorot_uniform', activation='relu')(x1)\n",
    "x2 = keras.layers.concatenate([tower1,tower2,tower3,tower4],axis=1)\n",
    "x2 = MaxPooling2D(pool_size=(3,3),padding='same', strides = (2,2))(x2)\n",
    "\n",
    "tower4 = Conv2D(filters = num_filter, kernel_size=(1,1),padding='same',kernel_initializer='glorot_uniform', activation='relu')(x2)\n",
    "tower4 = Conv2D(filters = num_filter, kernel_size=(3,3),padding='same',kernel_initializer='glorot_uniform', activation='relu')(tower4)\n",
    "\n",
    "tower5 = Conv2D(filters = num_filter, kernel_size=(1,1),padding='same',kernel_initializer='glorot_uniform', activation='relu')(x2)\n",
    "tower5 = Conv2D(filters = num_filter, kernel_size=(5,5),padding='same',kernel_initializer='glorot_uniform',activation='relu')(tower5)\n",
    "\n",
    "tower6 = MaxPooling2D(pool_size=(3,3),padding='same', strides = (1,1))(x2)\n",
    "tower6 = Conv2D(filters = num_filter, kernel_size=(3,3),padding='same',kernel_initializer='glorot_uniform',activation='relu')(tower6)\n",
    "\n",
    "tower7 = Conv2D(filters = num_filter, kernel_size=(3,3),padding='same',kernel_initializer='glorot_uniform', activation='relu')(x2)\n",
    "x3 = keras.layers.concatenate([tower4,tower5,tower6,tower7],axis=1)\n",
    "\n",
    "tower8 = Conv2D(filters = num_filter, kernel_size=(1,1),padding='same',kernel_initializer='glorot_uniform', activation='relu')(x3)\n",
    "tower8 = Conv2D(filters = num_filter, kernel_size=(3,3),padding='same',kernel_initializer='glorot_uniform', activation='relu')(tower8)\n",
    "\n",
    "tower9 = Conv2D(filters = num_filter, kernel_size=(1,1),padding='same',kernel_initializer='glorot_uniform', activation='relu')(x3)\n",
    "tower9 = Conv2D(filters = num_filter, kernel_size=(5,5),padding='same',kernel_initializer='glorot_uniform',activation='relu')(tower9)\n",
    "\n",
    "tower10 = MaxPooling2D(pool_size=(3,3),padding='same', strides = (1,1))(x3)\n",
    "tower10 = Conv2D(filters = num_filter, kernel_size=(3,3),padding='same',kernel_initializer='glorot_uniform',activation='relu')(tower10)\n",
    "\n",
    "tower11 = Conv2D(filters = num_filter, kernel_size=(3,3),padding='same',kernel_initializer='glorot_uniform', activation='relu')(x3)\n",
    "x4 = keras.layers.concatenate([tower8,tower9,tower10,tower11],axis=1)\n",
    "tower12 = Conv2D(filters = num_filter, kernel_size=(1,1),padding='same',kernel_initializer='glorot_uniform', activation='relu')(x4)\n",
    "tower12 = Conv2D(filters = num_filter, kernel_size=(3,3),padding='same',kernel_initializer='glorot_uniform', activation='relu')(tower12)\n",
    "\n",
    "tower13 = Conv2D(filters = num_filter, kernel_size=(1,1),padding='same',kernel_initializer='glorot_uniform', activation='relu')(x4)\n",
    "tower13 = Conv2D(filters = num_filter, kernel_size=(5,5),padding='same',kernel_initializer='glorot_uniform',activation='relu')(tower13)\n",
    "\n",
    "tower14 = MaxPooling2D(pool_size=(3,3),padding='same', strides = (1,1))(x4)\n",
    "tower14 = Conv2D(filters = num_filter, kernel_size=(3,3),padding='same',kernel_initializer='glorot_uniform',activation='relu')(tower14)\n",
    "\n",
    "tower15 = Conv2D(filters = num_filter, kernel_size=(3,3),padding='same',kernel_initializer='glorot_uniform', activation='relu')(x4)\n",
    "x = keras.layers.concatenate([tower12,tower13,tower14,tower15],axis=1)\n",
    "x = AveragePooling2D(pool_size=(5,5),padding='valid', strides = (3,3))(x4)\n",
    "x = Conv2D(64,(1,1))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024)(x)\n",
    "x = Dense(512)(x)\n",
    "x = Dense(num_classes)(x)\n",
    "output = Activation('softmax')(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([inputs],output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 61, 61, 8)    1184        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 31, 31, 8)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 31, 31, 8)    32          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 31, 31, 16)   144         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 29, 29, 32)   4640        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 29, 29, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 15, 15, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 15, 15, 64)   2112        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 15, 15, 64)   2112        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 15, 15, 32)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 15, 15, 64)   36928       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 15, 15, 64)   102464      conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 15, 15, 64)   18496       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 15, 15, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 60, 15, 64)   0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 30, 8, 64)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 30, 8, 64)    4160        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 30, 8, 64)    4160        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 30, 8, 64)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 30, 8, 64)    36928       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 30, 8, 64)    102464      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 30, 8, 64)    36928       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 30, 8, 64)    36928       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 120, 8, 64)   0           conv2d_11[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 120, 8, 64)   4160        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 120, 8, 64)   4160        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 120, 8, 64)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 120, 8, 64)   36928       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 120, 8, 64)   102464      conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 120, 8, 64)   36928       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 120, 8, 64)   36928       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 480, 8, 64)   0           conv2d_17[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 159, 2, 64)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 159, 2, 64)   4160        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 159, 2, 64)   0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 79, 1, 64)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 5056)         0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         5178368     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          524800      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 8)            4104        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 8)            0           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,341,304\n",
      "Trainable params: 6,341,224\n",
      "Non-trainable params: 80\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3600 samples, validate on 400 samples\n",
      "Epoch 1/100\n",
      "3600/3600 [==============================] - 18s 5ms/step - loss: 0.9661 - acc: 0.5858 - val_loss: 1.0175 - val_acc: 0.4900\n",
      "Epoch 2/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.8353 - acc: 0.6522 - val_loss: 1.0301 - val_acc: 0.4450\n",
      "Epoch 3/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.8178 - acc: 0.6717 - val_loss: 0.9343 - val_acc: 0.6525\n",
      "Epoch 4/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.8051 - acc: 0.6783 - val_loss: 0.9627 - val_acc: 0.5700\n",
      "Epoch 5/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7978 - acc: 0.6869 - val_loss: 0.9289 - val_acc: 0.6500\n",
      "Epoch 6/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7915 - acc: 0.6908 - val_loss: 0.9459 - val_acc: 0.5850\n",
      "Epoch 7/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7875 - acc: 0.6933 - val_loss: 0.9392 - val_acc: 0.5900\n",
      "Epoch 8/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7827 - acc: 0.6931 - val_loss: 0.9238 - val_acc: 0.6500\n",
      "Epoch 9/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7770 - acc: 0.6994 - val_loss: 0.9398 - val_acc: 0.5900TA: 4\n",
      "Epoch 10/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7762 - acc: 0.7103 - val_loss: 0.9308 - val_acc: 0.6275\n",
      "Epoch 11/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7714 - acc: 0.7036 - val_loss: 0.9381 - val_acc: 0.6000\n",
      "Epoch 12/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7701 - acc: 0.7058 - val_loss: 0.9296 - val_acc: 0.6175\n",
      "Epoch 13/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7689 - acc: 0.7089 - val_loss: 0.9416 - val_acc: 0.5900\n",
      "Epoch 14/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7645 - acc: 0.7064 - val_loss: 0.9236 - val_acc: 0.6300\n",
      "Epoch 15/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7622 - acc: 0.7114 - val_loss: 0.9279 - val_acc: 0.6150\n",
      "Epoch 16/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7605 - acc: 0.7167 - val_loss: 0.9309 - val_acc: 0.6125\n",
      "Epoch 17/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7599 - acc: 0.7117 - val_loss: 0.9283 - val_acc: 0.6125\n",
      "Epoch 18/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7568 - acc: 0.7175 - val_loss: 0.9458 - val_acc: 0.5925\n",
      "Epoch 19/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7565 - acc: 0.7078 - val_loss: 0.9311 - val_acc: 0.6000\n",
      "Epoch 20/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7538 - acc: 0.7158 - val_loss: 0.9298 - val_acc: 0.6125\n",
      "Epoch 21/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7532 - acc: 0.7186 - val_loss: 0.9287 - val_acc: 0.6125\n",
      "Epoch 22/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7529 - acc: 0.7158 - val_loss: 0.9272 - val_acc: 0.6125\n",
      "Epoch 23/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7504 - acc: 0.7128 - val_loss: 0.9258 - val_acc: 0.6150\n",
      "Epoch 24/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7497 - acc: 0.7111 - val_loss: 0.9295 - val_acc: 0.6025\n",
      "Epoch 25/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7500 - acc: 0.7156 - val_loss: 0.9327 - val_acc: 0.5925\n",
      "Epoch 26/100\n",
      "3600/3600 [==============================] - 18s 5ms/step - loss: 0.7468 - acc: 0.7131 - val_loss: 0.9180 - val_acc: 0.6275\n",
      "Epoch 27/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7468 - acc: 0.7203 - val_loss: 0.9355 - val_acc: 0.5975\n",
      "Epoch 28/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7464 - acc: 0.7233 - val_loss: 0.9340 - val_acc: 0.6000\n",
      "Epoch 29/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7444 - acc: 0.7200 - val_loss: 0.9220 - val_acc: 0.6175\n",
      "Epoch 30/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7452 - acc: 0.7189 - val_loss: 0.9260 - val_acc: 0.6100\n",
      "Epoch 31/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7426 - acc: 0.7169 - val_loss: 0.9249 - val_acc: 0.6100\n",
      "Epoch 32/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7417 - acc: 0.7242 - val_loss: 0.9313 - val_acc: 0.5975\n",
      "Epoch 33/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7422 - acc: 0.7189 - val_loss: 0.9357 - val_acc: 0.5975\n",
      "Epoch 34/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7421 - acc: 0.7222 - val_loss: 0.9175 - val_acc: 0.6175\n",
      "Epoch 35/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7406 - acc: 0.7214 - val_loss: 0.9290 - val_acc: 0.6000\n",
      "Epoch 36/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7400 - acc: 0.7219 - val_loss: 0.9249 - val_acc: 0.6025\n",
      "Epoch 37/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7383 - acc: 0.7236 - val_loss: 0.9217 - val_acc: 0.6100\n",
      "Epoch 38/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7370 - acc: 0.7217 - val_loss: 0.9226 - val_acc: 0.6100\n",
      "Epoch 39/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7382 - acc: 0.7183 - val_loss: 0.9228 - val_acc: 0.6075\n",
      "Epoch 40/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7365 - acc: 0.7183 - val_loss: 0.9244 - val_acc: 0.6050\n",
      "Epoch 41/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7358 - acc: 0.7214 - val_loss: 0.9215 - val_acc: 0.6100\n",
      "Epoch 42/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7355 - acc: 0.7244 - val_loss: 0.9178 - val_acc: 0.6125\n",
      "Epoch 43/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7351 - acc: 0.7222 - val_loss: 0.9161 - val_acc: 0.6150\n",
      "Epoch 44/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7349 - acc: 0.7239 - val_loss: 0.9226 - val_acc: 0.6075\n",
      "Epoch 45/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7345 - acc: 0.7269 - val_loss: 0.9169 - val_acc: 0.6125\n",
      "Epoch 46/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7333 - acc: 0.7239 - val_loss: 0.9269 - val_acc: 0.6000\n",
      "Epoch 47/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7328 - acc: 0.7208 - val_loss: 0.9190 - val_acc: 0.6100\n",
      "Epoch 48/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7326 - acc: 0.7178 - val_loss: 0.9221 - val_acc: 0.6075\n",
      "Epoch 49/100\n",
      "3600/3600 [==============================] - 16s 5ms/step - loss: 0.7312 - acc: 0.7258 - val_loss: 0.9240 - val_acc: 0.6025\n",
      "Epoch 50/100\n",
      "3600/3600 [==============================] - 16s 5ms/step - loss: 0.7306 - acc: 0.7264 - val_loss: 0.9184 - val_acc: 0.6100\n",
      "Epoch 51/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7318 - acc: 0.7214 - val_loss: 0.9206 - val_acc: 0.6075\n",
      "Epoch 52/100\n",
      "3600/3600 [==============================] - 16s 5ms/step - loss: 0.7291 - acc: 0.7222 - val_loss: 0.9197 - val_acc: 0.6050\n",
      "Epoch 53/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7279 - acc: 0.7239 - val_loss: 0.9170 - val_acc: 0.6100\n",
      "Epoch 54/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7297 - acc: 0.7278 - val_loss: 0.9163 - val_acc: 0.6100\n",
      "Epoch 55/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7280 - acc: 0.7231 - val_loss: 0.9156 - val_acc: 0.6125\n",
      "Epoch 56/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7310 - acc: 0.7239 - val_loss: 0.9188 - val_acc: 0.6050\n",
      "Epoch 57/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7277 - acc: 0.7244 - val_loss: 0.9227 - val_acc: 0.6125\n",
      "Epoch 58/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7277 - acc: 0.7244 - val_loss: 0.9212 - val_acc: 0.6125\n",
      "Epoch 59/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7277 - acc: 0.7281 - val_loss: 0.9199 - val_acc: 0.6075\n",
      "Epoch 60/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7274 - acc: 0.7272 - val_loss: 0.9144 - val_acc: 0.6150\n",
      "Epoch 61/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7288 - acc: 0.7264 - val_loss: 0.9186 - val_acc: 0.6100\n",
      "Epoch 62/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7260 - acc: 0.7269 - val_loss: 0.9187 - val_acc: 0.6100\n",
      "Epoch 63/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7245 - acc: 0.7264 - val_loss: 0.9168 - val_acc: 0.6075\n",
      "Epoch 64/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7257 - acc: 0.7250 - val_loss: 0.9183 - val_acc: 0.6100\n",
      "Epoch 65/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7247 - acc: 0.7281 - val_loss: 0.9194 - val_acc: 0.6100\n",
      "Epoch 66/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7235 - acc: 0.7283 - val_loss: 0.9118 - val_acc: 0.6200\n",
      "Epoch 67/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7267 - acc: 0.7272 - val_loss: 0.9147 - val_acc: 0.6100\n",
      "Epoch 68/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7232 - acc: 0.7278 - val_loss: 0.9150 - val_acc: 0.6100\n",
      "Epoch 69/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7232 - acc: 0.7292 - val_loss: 0.9165 - val_acc: 0.6050\n",
      "Epoch 70/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7225 - acc: 0.7281 - val_loss: 0.9133 - val_acc: 0.6125\n",
      "Epoch 71/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7223 - acc: 0.7314 - val_loss: 0.9147 - val_acc: 0.6100\n",
      "Epoch 72/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7222 - acc: 0.7300 - val_loss: 0.9145 - val_acc: 0.6100\n",
      "Epoch 73/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7229 - acc: 0.7269 - val_loss: 0.9163 - val_acc: 0.6100\n",
      "Epoch 74/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7207 - acc: 0.7311 - val_loss: 0.9167 - val_acc: 0.6100\n",
      "Epoch 75/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7226 - acc: 0.7269 - val_loss: 0.9126 - val_acc: 0.6125\n",
      "Epoch 76/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7210 - acc: 0.7281 - val_loss: 0.9129 - val_acc: 0.6125\n",
      "Epoch 77/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7216 - acc: 0.7292 - val_loss: 0.9115 - val_acc: 0.6175\n",
      "Epoch 78/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7219 - acc: 0.7311 - val_loss: 0.9138 - val_acc: 0.6100\n",
      "Epoch 79/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7192 - acc: 0.7314 - val_loss: 0.9096 - val_acc: 0.6250\n",
      "Epoch 80/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7192 - acc: 0.7319 - val_loss: 0.9096 - val_acc: 0.6250\n",
      "Epoch 81/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7190 - acc: 0.7250 - val_loss: 0.9137 - val_acc: 0.6075\n",
      "Epoch 82/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7192 - acc: 0.7319 - val_loss: 0.9141 - val_acc: 0.6100\n",
      "Epoch 83/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7189 - acc: 0.7297 - val_loss: 0.9147 - val_acc: 0.6125\n",
      "Epoch 84/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7190 - acc: 0.7289 - val_loss: 0.9132 - val_acc: 0.6075\n",
      "Epoch 85/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7177 - acc: 0.7325 - val_loss: 0.9154 - val_acc: 0.6125\n",
      "Epoch 86/100\n",
      "3600/3600 [==============================] - 16s 5ms/step - loss: 0.7171 - acc: 0.7294 - val_loss: 0.9135 - val_acc: 0.6100\n",
      "Epoch 87/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7176 - acc: 0.7303 - val_loss: 0.9151 - val_acc: 0.6125\n",
      "Epoch 88/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7173 - acc: 0.7314 - val_loss: 0.9145 - val_acc: 0.6100\n",
      "Epoch 89/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7179 - acc: 0.7283 - val_loss: 0.9132 - val_acc: 0.6100\n",
      "Epoch 90/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7178 - acc: 0.7314 - val_loss: 0.9103 - val_acc: 0.6150\n",
      "Epoch 91/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7165 - acc: 0.7331 - val_loss: 0.9102 - val_acc: 0.6125\n",
      "Epoch 92/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7162 - acc: 0.7347 - val_loss: 0.9104 - val_acc: 0.6125\n",
      "Epoch 93/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7154 - acc: 0.7314 - val_loss: 0.9122 - val_acc: 0.6125\n",
      "Epoch 94/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7159 - acc: 0.7275 - val_loss: 0.9141 - val_acc: 0.6125\n",
      "Epoch 95/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7147 - acc: 0.7333 - val_loss: 0.9102 - val_acc: 0.6150\n",
      "Epoch 96/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7159 - acc: 0.7319 - val_loss: 0.9086 - val_acc: 0.6175\n",
      "Epoch 97/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7151 - acc: 0.7333 - val_loss: 0.9112 - val_acc: 0.6125\n",
      "Epoch 98/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7139 - acc: 0.7306 - val_loss: 0.9119 - val_acc: 0.6125\n",
      "Epoch 99/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7162 - acc: 0.7297 - val_loss: 0.9140 - val_acc: 0.6125\n",
      "Epoch 100/100\n",
      "3600/3600 [==============================] - 17s 5ms/step - loss: 0.7133 - acc: 0.7339 - val_loss: 0.9101 - val_acc: 0.6125\n",
      "Test loss: 0.892379063129\n",
      "Test accuracy: 0.650000000477\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=0.0001,decay=1e-1)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "model.fit(X_train,y1,batch_size=30,epochs=100,validation_split=0.1,shuffle=True)\n",
    "score = model.evaluate(X_test, y2, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights('model.h5')\n",
    "print('Saved model to disk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
